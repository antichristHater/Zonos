{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the dataset / TODO: fix this mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from AudioInfo import Ses, SesFromArray\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_dset(size = 10000):\n",
    "    dset = {}\n",
    "    pth = '0-10000.json'\n",
    "    if os.path.exists(pth):\n",
    "        with open(pth, 'r', encoding='utf-8') as file:\n",
    "            dset = json.loads(file.read())\n",
    "    else:\n",
    "        for d in tqdm(range(0, size, 1000)): # Save RAM space by loading in 1000 element chunks\n",
    "            dataset = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"tr\", split=f\"train[{d}:{d+1000}]\")\n",
    "            for idx, (audio, sentence) in enumerate(zip(dataset['audio'], dataset['sentence'])):\n",
    "                dset[idx+d] = {\"path\": audio['path'], \"sentence\": sentence}\n",
    "    return dset\n",
    "\n",
    "dset = load_dset(10000)\n",
    "dset = {int(k): v for k, v in dset.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the Zonos model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initing zonos for ft\n"
     ]
    }
   ],
   "source": [
    "from AudioInfo import Ses, SesFromArray\n",
    "import torch\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "from zonos.codebook_pattern import apply_delay_pattern, revert_delay_pattern\n",
    "from huggingface_hub import hf_hub_download\n",
    "from zonos.sampling import sample_from_logits\n",
    "from tqdm import tqdm\n",
    "model_path=\"Zyphra/Zonos-v0.1-transformer\"\n",
    "dataset_name=\"mozilla-foundation/common_voice_17_0\"\n",
    "device = 'cuda'\n",
    "\n",
    "model = Zonos.from_pretrained(model_path, device=device)\n",
    "cfg_scale = 2\n",
    "sampling_params = dict(min_p=0.1)\n",
    "cg = model.can_use_cudagraphs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Funcs to grab & preprocess input audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silero_vad import load_silero_vad, get_speech_timestamps\n",
    "silero_model = load_silero_vad()\n",
    "\n",
    "def audio_to_prefix_code(arr, sr):\n",
    "    wav_prefix, sr_prefix = torch.tensor(arr, dtype=torch.float32).unsqueeze(0), sr\n",
    "    wav_prefix = wav_prefix.mean(0, keepdim=True)\n",
    "    wav_prefix = model.autoencoder.preprocess(wav_prefix, sr_prefix)\n",
    "    wav_prefix = wav_prefix.to(device, dtype=torch.float32)\n",
    "    return model.autoencoder.encode(wav_prefix.unsqueeze(0))\n",
    "\n",
    "def ses_to_prefix_code(ses: Ses):\n",
    "    if sum(torch.tensor(ses.arr)) != 0:\n",
    "            return audio_to_prefix_code(ses.arr, ses.sr)\n",
    "    else:\n",
    "        print(\"passed empty prefix\")\n",
    "        return torch.full((1,9,0), 0).to(model.device)\n",
    "\n",
    "def get_stamps(ses:Ses):\n",
    "    if ses.sr != 16000:\n",
    "        ses = ses.resampled(16000)\n",
    "    speech_timestamps = get_speech_timestamps(\n",
    "        torch.tensor(ses.arr, dtype=torch.float32),\n",
    "        silero_model,\n",
    "        return_seconds=True,  # Return speech timestamps in seconds (default is samples)\n",
    "    )\n",
    "    if len(speech_timestamps) < 1: return False\n",
    "    return speech_timestamps[0]['start'], speech_timestamps[-1]['end']\n",
    "\n",
    "def idx_to_condition(idx: int, limit=15):\n",
    "    ses = Ses(dset[idx]['path']).resampled(44100) #\n",
    "    if ses.duration_ > limit:\n",
    "        ses = ses.trimmed(0, limit)\n",
    "    start, end = get_stamps(ses) # stamps do round and sometimes raise errors, fix that.\n",
    "    ses = ses.trimmed(start, end-start) # note: trimmed takes `t` as second element, not `end`\n",
    "    sentence = dset[idx]['sentence']\n",
    "\n",
    "    tens_ = torch.tensor(ses.arr, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    new_condt = make_cond_dict(\n",
    "        text=sentence,\n",
    "        speaker=model.make_speaker_embedding(tens_.squeeze(), ses.sr),\n",
    "        language='tr',#lang_1,\n",
    "    )\n",
    "\n",
    "    # ses = ses.trimmed(0, 1.5)\n",
    "    prefix_codes = ses_to_prefix_code(ses)\n",
    "    prefix_conditioning = model.prepare_conditioning(new_condt)\n",
    "\n",
    "    return prefix_codes, prefix_conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Prefill with the input audio codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_prefix(codes: torch.Tensor, prefix_conditioning=None, trim:None|int=None):\n",
    "    assert isinstance(prefix_conditioning, torch.Tensor)\n",
    "    if isinstance(codes, Ses):\n",
    "        codes = ses_to_prefix_code(codes) # if a `Ses` instance, process\n",
    "    assert isinstance(codes, torch.Tensor)\n",
    "    # Encode input audio\n",
    "    prefix_codes = codes\n",
    "    p_len = prefix_codes.size(-1)\n",
    "    # Hyperparams\n",
    "    max_length = 86 * 30\n",
    "    seq_len = p_len + max_length + 9\n",
    "    # Inference params\n",
    "    with torch.device(model.device):\n",
    "        batch_size__ = 1\n",
    "        unknown_token = -1\n",
    "        inference_params = model.setup_cache(batch_size=batch_size__ * 2, max_seqlen=seq_len)\n",
    "    # Inference mode (no gradients are needed)\n",
    "    with torch.no_grad():\n",
    "        # Prepare prefix codes\n",
    "        p_padded = torch.nn.functional.pad(prefix_codes, (0, max_length + p_len), value=unknown_token)\n",
    "        # Re-predict missing token\n",
    "        p_delayed = apply_delay_pattern(p_padded, mask_token=model.masked_token_id)\n",
    "        pred_idx = p_len if trim is None else trim\n",
    "        logits = model._prefill(prefix_conditioning,\n",
    "                                p_delayed[...,:pred_idx + 1],\n",
    "                                inference_params, 2)\n",
    "        next_token = sample_from_logits(logits, **sampling_params)\n",
    "\n",
    "        frame = p_delayed[..., pred_idx + 1:pred_idx + 2]\n",
    "        frame.masked_scatter_(frame == unknown_token, next_token)\n",
    "    # Offset and logit\n",
    "    offset = p_delayed[...,:pred_idx + 1].size(-1)\n",
    "    logit_bias = torch.zeros_like(logits)\n",
    "    logit_bias[:, 1:, model.eos_token_id] = -torch.inf\n",
    "    # Inference params\n",
    "    prefices_length = prefix_conditioning.shape[1] + pred_idx + 1\n",
    "    inference_params.seqlen_offset += prefices_length\n",
    "    inference_params.lengths_per_sample[:] += prefices_length\n",
    "    to_compare = p_delayed[...,offset+1:offset+2]\n",
    "    return p_delayed, inference_params, offset, logit_bias, to_compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "import random\n",
    "\n",
    "# Params\n",
    "loss_list = []\n",
    "total_loss = 0\n",
    "total_loss_ctr = 0\n",
    "\n",
    "'''loss_per_second: the amount of input to process every 86 frames'''\n",
    "loss_per_second = 1 # \n",
    "counter = 0\n",
    "desc = ''\n",
    "progress = tqdm(dset.keys(), desc=f\"desc: {desc}\")\n",
    "STAYED_AT = 0 # in case of restart\n",
    "\n",
    "# Optimize & scheduler\n",
    "learning_rate = 1e-4\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=learning_rate,\n",
    "        epochs=1,\n",
    "        steps_per_epoch= (len(dset) - STAYED_AT) * loss_per_second * 5, # Assumed each input is 5 seconds on average, fix this later\n",
    "        pct_start=0.1\n",
    "    )\n",
    "\n",
    "# Training loop\n",
    "for k in progress:\n",
    "    if k < STAYED_AT:\n",
    "        continue\n",
    "    optimizer.zero_grad()\n",
    "    # Grab input audio\n",
    "    codes, cond = idx_to_condition(k, limit=25)\n",
    "    duration = codes.size(-1)\n",
    "\n",
    "    batch_loss = 0\n",
    "    batch_loss_ctr = 0\n",
    "    batch_size = len(list(range(0, codes.size(-1), int(86/loss_per_second))))\n",
    "\n",
    "    for duration_idx in range(0, codes.size(-1), int(86/loss_per_second)):\n",
    "        # Don't take first couple and last couple frames into accounts for now.\n",
    "        if duration_idx < 10 or duration - duration_idx < 5:\n",
    "            continue\n",
    "        try: random_index = random.randint(9, codes.size(-1)-9)\n",
    "        except: random_index = duration_idx\n",
    "        \n",
    "        optimizer.zero_grad()  # Reset gradients for each batch\n",
    "\n",
    "        # 1. Input codes \n",
    "        with torch.no_grad():\n",
    "            delayed_codes, inference_params, offset, logit_bias, to_compare = prepare_prefix(codes, cond, random_index) # duration_idx)\n",
    "            offset += 1\n",
    "        \n",
    "        # 2. Get logits\n",
    "        input_ids = delayed_codes[..., offset - 1 : offset]  # Shape: [9,1]\n",
    "        logits = model._decode_one_token(input_ids, inference_params, cfg_scale, allow_cudagraphs=cg)  # Shape: [1, 9, 1026]\n",
    "\n",
    "        # 3. Compute loss\n",
    "        loss = torch.nn.functional.cross_entropy(logits.squeeze(), to_compare.squeeze())\n",
    "\n",
    "        # 4. Debug\n",
    "        total_loss += loss.item()\n",
    "        total_loss_ctr += 1\n",
    "        batch_loss += loss.item()\n",
    "        batch_loss_ctr += 1\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        progress.desc = f\"now @ key {k} & {batch_loss_ctr+1}/{batch_size} | idx @ {random_index}/{codes.size(-1)-9} | total processed: {total_loss_ctr} | loss: {loss.item()} | batch avg loss: {batch_loss/(batch_loss_ctr if batch_loss_ctr != 0 else 1)} |total avg loss: {total_loss/(total_loss_ctr if total_loss_ctr != 0 else 1)}\"\n",
    "        progress.update()\n",
    "\n",
    "        # 5. Backward\n",
    "        loss.backward(); del loss; torch.cuda.empty_cache() # They accumulate for some reason TODO: dig into this\n",
    "        optimizer.step()  # Update weights\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Save loss history\n",
    "    try:\n",
    "        with open('loss_data.json', 'w', encoding='utf-8') as file:\n",
    "            file.write(json.dumps(loss_list))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed empty prefix\n"
     ]
    }
   ],
   "source": [
    "new_condt = make_cond_dict(\n",
    "        text= \"Merhaba beyefendi, adınız nedir?\",\n",
    "        language='tr',\n",
    "    )\n",
    "\n",
    "# To do audio completion\n",
    "ses_ = Ses('sample.wav')\n",
    "prefix_codes = ses_to_prefix_code(ses_)\n",
    "prefix_conditioning = model.prepare_conditioning(new_condt)\n",
    "\n",
    "# Empty input to generate audios from no prefices\n",
    "empty_ses = SesFromArray(torch.tensor(()).to(torch.float64).numpy(), 6)\n",
    "with torch.no_grad():\n",
    "    delayed_codes, inference_params, offset, logit_bias, to_compare = prepare_prefix(empty_ses, prefix_conditioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [00:21<00:00, 12.22it/s]\n"
     ]
    }
   ],
   "source": [
    "SECONDS_TO_GENERATE = 3\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(86*SECONDS_TO_GENERATE)):\n",
    "        # Increase offset / Offseti artır\n",
    "        offset += 1\n",
    "\n",
    "        # Calculate next logit / Sonraki logiti hesapla\n",
    "        input_ids = delayed_codes[..., offset - 1 : offset] # tensor([ 698, 1025, 1025, 1025, 1025, 1025, 1025, 1025, 1025], device='cuda:0') [9, 1]; 698 next_tokenin 0. elemanıydı.\n",
    "        logits = model._decode_one_token(input_ids, inference_params, cfg_scale, allow_cudagraphs=cg) # torch.Size([1, 9, 1026]); \n",
    "        logits += logit_bias # decode_one_token'in son elementlerinde [1025ler] olasılık zaten -inf'di. \n",
    "        next_token = sample_from_logits(logits, generated_tokens=delayed_codes[..., :offset], **sampling_params)\n",
    "\n",
    "        # Append the new token / Yeni tokeni ekle\n",
    "        frame = delayed_codes[..., offset : offset + 1]\n",
    "        frame.masked_scatter_(frame == -1, next_token)\n",
    "\n",
    "        # Increase inference_params / Inference ayarla.\n",
    "        inference_params.seqlen_offset += 1\n",
    "        inference_params.lengths_per_sample[:] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 250])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Make this a function\n",
    "with torch.no_grad():\n",
    "    out_codes = revert_delay_pattern(delayed_codes)\n",
    "    out_codes.masked_fill_(out_codes >= 1024, 0)\n",
    "    out_codes = out_codes[..., : offset - 9]\n",
    "    print(out_codes.shape)\n",
    "    decodedarr = model.autoencoder.decode(out_codes).squeeze().to(torch.float64).cpu()\n",
    "    SesFromArray(decodedarr.numpy(), 44100).write('turkish demo.wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
